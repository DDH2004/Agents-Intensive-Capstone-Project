{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a7e12c",
   "metadata": {},
   "source": [
    "## Setup and Dependencies\n",
    "This section installs the necessary libraries and configures the Gemini API key.\n",
    "\n",
    "- google-generativeai: For accessing the Gemini LLM.\n",
    "\n",
    "- pypdf: For extracting text from PDF files.\n",
    "\n",
    "- pandas: Used here for handling data, though mainly for structure/potential future use (though not strictly required for the core logic).\n",
    "\n",
    "- ipywidgets: For creating the interactive display of flashcards in a notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-generativeai pypdf pandas ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from pypdf import PdfReader\n",
    "import textwrap\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"AIzaSyAcxISd3mLcBfJ46yeIh01lS6gU9b6PTJI\")\n",
    "\n",
    "MODEL = \"gemini-2.5-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004c1dfe",
   "metadata": {},
   "source": [
    "## Core Utilities: I/O and Chunking\n",
    "These helper functions manage reading the PDF file and splitting the raw text into model-safe chunks.\n",
    "- read_pdf: Extracts all text from a PDF file page-by-page.\n",
    "- chunk_text: Splits the long, raw text into smaller sections (default $\\approx$ 6000 characters) to avoid exceeding the LLM's context window and to ensure focused summarization.\n",
    "- call_llm: A simple wrapper function to call the Gemini model with a specified prompt and temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    reader = PdfReader(path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "\n",
    "def chunk_text(text, max_chars=6000):\n",
    "    \"\"\"Splits long text into model-safe chunks.\"\"\"\n",
    "    chunks = []\n",
    "    current = []\n",
    "    current_len = 0\n",
    "\n",
    "    for line in text.split(\"\\n\"):\n",
    "        if current_len + len(line) > max_chars:\n",
    "            chunks.append(\"\\n\".join(current))\n",
    "            current = []\n",
    "            current_len = 0\n",
    "        current.append(line)\n",
    "        current_len += len(line)\n",
    "\n",
    "    if current:\n",
    "        chunks.append(\"\\n\".join(current))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def call_llm(prompt, temperature=0.2):\n",
    "    \"\"\"Single wrapper for Gemini calls.\"\"\"\n",
    "    response = genai.GenerativeModel(MODEL).generate_content(\n",
    "        prompt,\n",
    "        generation_config={\"temperature\": temperature}\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1e4c00",
   "metadata": {},
   "source": [
    "## Sequential Agent Pipeline\n",
    "This project uses two distinct LLM agents operating in sequence: the Summarization Agent and the Flashcard Agent.\n",
    "\n",
    "1. Summarization Agent\n",
    "\n",
    "\n",
    "This agent takes a chunk of text and transforms it into structured Markdown notes, focusing only on key educational elements (concepts, definitions, examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization_agent(chunk):\n",
    "    prompt = f\"\"\"\n",
    "You are a Summarization Agent.\n",
    "\n",
    "Summarize the following content into clear, structured study notes.\n",
    "Focus on:\n",
    "- Key concepts\n",
    "- Definitions\n",
    "- Examples\n",
    "- Important relationships\n",
    "- Remove irrelevant text\n",
    "\n",
    "Return only the notes.\n",
    "\n",
    "Content:\n",
    "{chunk}\n",
    "\"\"\"\n",
    "    return call_llm(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3905ae1c",
   "metadata": {},
   "source": [
    "2. Flashcard Agent\n",
    "\n",
    "\n",
    "This agent takes the output from the Summarization Agent (the structured notes) and generates concise question-answer pairs in a clean JSON format. This structure is crucial for easy parsing and interactive display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17279e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flashcard_agent(notes):\n",
    "    prompt = f\"\"\"\n",
    "You are a Flashcard Agent.\n",
    "\n",
    "Create concise flashcards from the following study notes.\n",
    "Output JSON list like:\n",
    "\n",
    "[\n",
    "  {{\"question\": \"...\", \"answer\": \"...\"}},\n",
    "  ...\n",
    "]\n",
    "\n",
    "Notes:\n",
    "{notes}\n",
    "\"\"\"\n",
    "    output = call_llm(prompt)\n",
    "    try:\n",
    "        return json.loads(output)\n",
    "    except:\n",
    "        # fallback: model sometimes outputs markdown\n",
    "        return json.loads(output.strip().strip(\"```json\").strip(\"```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549f63a",
   "metadata": {},
   "source": [
    "## Main Processing Function\n",
    "\n",
    "The process_file function orchestrates the entire workflow: reading, chunking, running agents sequentially, and combining results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path):\n",
    "    print(\"Reading file...\")\n",
    "    text = read_pdf(file_path) if file_path.endswith(\".pdf\") else open(file_path).read()\n",
    "\n",
    "    print(\"Chunking...\")\n",
    "    chunks = chunk_text(text)\n",
    "\n",
    "    print(f\"Processing {len(chunks)} chunks...\\n\")\n",
    "    all_notes = []\n",
    "\n",
    "    # Run the summarization agent sequentially\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Summarizing chunk {i+1} / {len(chunks)}...\")\n",
    "        summary = summarization_agent(chunk)\n",
    "        all_notes.append(summary)\n",
    "\n",
    "    full_notes = \"\\n\\n\".join(all_notes)\n",
    "\n",
    "    print(\"Generating flashcards...\")\n",
    "    flashcards = flashcard_agent(full_notes)\n",
    "\n",
    "    return full_notes, flashcards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab17afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_notes, flashcards = process_file('sample.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ac4cd",
   "metadata": {},
   "source": [
    "## Interactive Display (IPywidgets)\n",
    "This final section uses ipywidgets and IPython.display to render the results interactively in the Jupyter Notebook.\n",
    "\n",
    "- The Structured Notes are displayed directly using Markdown formatting.\n",
    "\n",
    "- The Flashcards are displayed using Accordion widgets, allowing users to see the question and click to reveal the answer for active recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d917cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from ipywidgets import Accordion, HTML, VBox\n",
    "import pandas as pd\n",
    "\n",
    "def show_notes(notes):\n",
    "    display(Markdown(f\"## ðŸ“˜ Study Notes\\n\\n{notes}\"))\n",
    "\n",
    "def show_flashcards(cards):\n",
    "    items = []\n",
    "    for c in cards:\n",
    "        q = HTML(f\"<b>Q:</b> {c['question']}\")\n",
    "        a = HTML(f\"<b>A:</b> {c['answer']}\")\n",
    "        items.append(VBox([q, a]))\n",
    "\n",
    "    accordion = Accordion(children=items)\n",
    "\n",
    "    for i, c in enumerate(cards):\n",
    "        accordion.set_title(i, f\"Card {i+1}\")\n",
    "\n",
    "    return accordion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_notes(full_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_flashcards(flashcards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
